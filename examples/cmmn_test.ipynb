{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook is for testing Convolutional Monge Mapping Normalization (hereafter, CMMN) - (put link here).\n",
    "\n",
    "The goal is that this will improve the performance of the clf we've trained on the emotion dataset when applied to the cue dataset, even though the confusion matrix won't line up perfectly (rectangular, with slightly different classes).\n",
    "\n",
    "An outline of how this works:\n",
    "1. Load all emotion dataset, and chunk it into 30 second intervals (note - time increment doesn't matter, as long as it's consistent. But I'll stick with what they chose in their demo for now).\n",
    "2. Load all cue dataset, and chunk it into 30 second intervals.\n",
    "3. Fit the CMMN to the emotion dataset, then transform the cue dataset.\n",
    "4. Reconstruct the cue dataset into its original form of ICs per subj.\n",
    "5. Use the emotion clf on the cue dataset, take conf matrix.\n",
    "5a. Additionally, take PSD and count vectors of cue before and after CMMN."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3dab3cc77442777"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from skorch.helper import predefined_split\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.dataset import Dataset\n",
    "\n",
    "from braindecode.models import SleepStagerChambon2018\n",
    "\n",
    "\n",
    "import mne\n",
    "from mne.datasets.sleep_physionet.age import fetch_data\n",
    "\n",
    "from cmmn.data import load_sleep_physionet, extract_epochs\n",
    "from cmmn import CMMN\n",
    "\n",
    "# their tutorial imports above, my imports below\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# emotion only missing subj 22\n",
    "emotion_subj_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35']\n",
    "\n",
    "cue_subj_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T19:41:45.573095539Z",
     "start_time": "2024-02-08T19:41:45.527940463Z"
    }
   },
   "id": "75eab86f70a5243c",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the data below. It should be fine to use absolute imports here.\n",
    "\n",
    "Notes on the dataset - \n",
    "sampling frequency = 256 hz\n",
    "\n",
    "The emotion dataset is natively 256 hz, and I've resampled cue to 256 hz and then done a hp filter of 1 hz to match the data preprocessing of the emotion dataset.\n",
    "\n",
    "As the data is loaded below, ICA still needs to be calculated. They store things in slightly different structs, so the process is slightly different for each.\n",
    "\n",
    "Also, there is a different number of channels per each - emotion has 224 and cue has 63. \n",
    "\n",
    "Note - this is taking too long. Save the activations after each in a new npz and then load in later piecemeal."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fca88260bf291687"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "# emotion only missing subj 22\n",
    "emotion_subj_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35']\n",
    "\n",
    "cue_subj_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "# single_subj_emotion_test_load = loadmat('/home/austin/PycharmProjects/BOWaves/data/ds003004/after_processing/subj-01.mat')\n",
    "# single_subj_cue_test_load = loadmat('/home/austin/PycharmProjects/BOWaves/data/codebooks/frolich/frolich_extract_subj_01_resampled_to_mice_hp_filtered.mat')\n",
    "\n",
    "emotion_subj_tensors = []\n",
    "cue_subj_tensors = []\n",
    "cue_labels_per_subj_per_ic = []\n",
    "\n",
    "for subj in emotion_subj_list:\n",
    "    subj_data = loadmat(f'/home/austin/PycharmProjects/BOWaves/data/ds003004/after_processing/subj-{subj}.mat')\n",
    "    icasphere = subj_data['icasphere']\n",
    "    icaweights = subj_data['icaweights']\n",
    "    data = subj_data['data']\n",
    "    \n",
    "    # ica\n",
    "    icaact = icaweights @ icasphere @ data # resulting shape is [224, length in 256 hz]\n",
    "    \n",
    "    # put into tensor of shape [224, length in 256 hz]\n",
    "    icaact = torch.tensor(icaact)#.unsqueeze(0)\n",
    "    \n",
    "    # # append to list\n",
    "    # emotion_subj_tensors.append(icaact)\n",
    "    \n",
    "    # save to npz\n",
    "    np.savez(f'/home/austin/PycharmProjects/BOWaves/data/cmmn_transformed_cue_to_emotion_ics/emotion_subj_{subj}.npz', icaact=icaact)\n",
    "\n",
    "for subj in cue_subj_list:\n",
    "    subj_data = loadmat(f'/home/austin/PycharmProjects/BOWaves/data/codebooks/frolich/frolich_extract_subj_{subj}_resampled_to_mice_hp_filtered.mat')\n",
    "    icaweights = subj_data['W']\n",
    "    data = subj_data['X']\n",
    "    \n",
    "    icaact = icaweights @ data # resulting shape is [63, length in 256 hz]\n",
    "    \n",
    "    # put into tensor of shape [63, length in 256 hz]\n",
    "    icaact = torch.tensor(icaact)#.unsqueeze(0)\n",
    "    \n",
    "    # # append to list\n",
    "    # cue_subj_tensors.append(icaact)\n",
    "    \n",
    "    # get labels\n",
    "    labels = subj_data['labels']\n",
    "    \n",
    "    # transform labels from ndarray of lists to list of ints\n",
    "    labels = [int(label[0]) for label in labels]\n",
    "    \n",
    "    cue_labels_per_subj_per_ic.append(labels)\n",
    "    \n",
    "    # save to npz\n",
    "    np.savez(f'/home/austin/PycharmProjects/BOWaves/data/cmmn_transformed_cue_to_emotion_ics/cue_subj_{subj}.npz', icaact=icaact, labels=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T16:03:01.471083615Z",
     "start_time": "2024-02-08T15:55:41.713589399Z"
    }
   },
   "id": "e228987efd156739",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reshape the data.\n",
    "\n",
    "The end result should be a list of tensors, where each tensor is of size (K, C, T).\n",
    "C is the number of channels - which should be 63 here since they've been through ICA but double check.\n",
    "T is the number of time points - this will just be whatever 30 seconds is in terms of the sampling rate.\n",
    "K is the number of 30 second chunks. This will be different for each subj.\n",
    "\n",
    "For whatever remainder there is of total_time - K*T, just disregard. Over these time scales it should be no issue.\n",
    "\n",
    "Due to memory constraints, load the ics in piecemeal, chunk them, and save the chunks again.\n",
    "Do the reshaping one at a time for emotion and for cue."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6460c7a1201413d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note - should I do this before or after ICA is applied? Think about it for a sec.\n",
    "Each channel should still be the same time length as the original dataset. So that isn't an issue. \n",
    "\n",
    "But for what's termed each 'source domain' in the paper - meaning every 30 second chunk that has N channels, they take the PSD. Does it make sense to take the PSD of the individual channels? \n",
    "\n",
    "I think it'll be fine to take the PSD after ICA - that's what we want to map to and from. I'll double check with my coauthors after this."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53683ed4d965d6c0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "\n",
    "# 30 seconds in 256 hz is 7680\n",
    "\n",
    "emotion_chunked = [] # list of tensors of shape (K, C, T)\n",
    "cue_chunked = [] # list of tensors of shape (K, C, T)\n",
    "\n",
    "emotion_subj_tensors = []\n",
    "#emotion_subj_list = ['01']#, '02', '03', '04', '05', '06', '07', '08', '09', '10']\n",
    "emotion_subj_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35']\n",
    "cue_subj_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "# load in emotion_subj_tensors\n",
    "# for subj in emotion_subj_list:\n",
    "#     subj_data = np.load(f'/home/austin/PycharmProjects/BOWaves/data/cmmn_transformed_cue_to_emotion_ics/emotion_subj_{subj}.npz')\n",
    "#     icaact = subj_data['icaact']\n",
    "#     #subj = icaact\n",
    "# #     emotion_subj_tensors.append(icaact)\n",
    "# # \n",
    "# # for subj in emotion_subj_tensors:\n",
    "# #     size = subj.shape[1]\n",
    "# #     num_chunks = size // 7680\n",
    "# #     #subj = subj.squeeze(0)\n",
    "# #     subj = subj[:, :7680*num_chunks]\n",
    "# #     subj = subj.reshape(-1, 224, 7680)\n",
    "#     #emotion_chunked.append(subj)\n",
    "#     num_channels, size = icaact.shape\n",
    "#     num_chunks = size // 7680\n",
    "#     #subj = subj.squeeze(0)\n",
    "#     \n",
    "#     print('shape:', icaact.shape)\n",
    "#     print('num_chunks:', num_chunks)\n",
    "#     icaact = icaact[:, :7680*num_chunks]\n",
    "#     icaact = icaact.reshape(-1, num_channels, 7680)\n",
    "#     np.savez(f'/home/austin/PycharmProjects/BOWaves/data/cmmn_transformed_cue_to_emotion_ics/emotion_subj_{subj}_chunked.npz', icaact=icaact)\n",
    "#     \n",
    "for subj in cue_subj_list:\n",
    "    subj_data = np.load(f'/home/austin/PycharmProjects/BOWaves/data/cmmn_transformed_cue_to_emotion_ics/cue_subj_{subj}.npz')\n",
    "    icaact = subj_data['icaact']\n",
    "    labels = subj_data['labels']\n",
    "    #subj = icaact\n",
    "    num_channels, size = icaact.shape\n",
    "    num_chunks = size // 7680\n",
    "    #subj = subj.squeeze(0)\n",
    "    icaact = icaact[:, :7680*num_chunks]\n",
    "    icaact = icaact.reshape(-1, num_channels, 7680)\n",
    "    np.savez(f'/home/austin/PycharmProjects/BOWaves/data/cmmn_transformed_cue_to_emotion_ics/cue_subj_{subj}_chunked.npz', icaact=icaact, labels=labels)\n",
    "\n",
    "# save the chunked data as one file\n",
    "#np.savez('/home/austin/PycharmProjects/BOWaves/data/cmmn_transformed_cue_to_emotion_ics/emotion_chunked.npz', *emotion_chunked) # taking a while - may fit the transform on ~10 subj.s only\n",
    "    \n",
    "# for subj in cue_subj_tensors:\n",
    "#     size = subj.shape[2]\n",
    "#     num_chunks = size // 7680\n",
    "#     #subj = subj.squeeze(0)\n",
    "#     subj = subj[:, :7680*num_chunks]\n",
    "#     subj = subj.reshape(-1, 63, 7680)\n",
    "#     cue_chunked.append(subj)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T21:37:16.441684302Z",
     "start_time": "2024-02-08T21:36:57.039459013Z"
    }
   },
   "id": "52466fcc11efe05f",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fit the CMMN to the emotion dataset, then transform the cue dataset.\n",
    "\n",
    "This make take a bit of time, especially considering the size of the dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc746145274b89a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Fit the CMMN to the emotion dataset, then transform the cue dataset\n",
    "# not enough ram on my machine, only 32 gigs. need to use Caviness.\n",
    "\n",
    "cmmn = CMMN()\n",
    "cmmn.fit(emotion_chunked)\n",
    "cue_chunked_transformed = cmmn.transform(cue_chunked)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-07T20:53:20.342650058Z"
    }
   },
   "id": "ce9a42d3a292f0a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reconstruct the cue dataset into its original form of ICs per subj.\n",
    "\n",
    "Then save this data. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80c1cba419cb533"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Reconstruct the cue dataset into its original form of ICs per subj\n",
    "cue_reconstructed = []\n",
    "\n",
    "for subj in cue_chunked_transformed:\n",
    "    subj = subj.reshape(63, -1)\n",
    "    cue_reconstructed.append(subj)\n",
    "\n",
    "# save the data with np.savez, including with labels\n",
    "for subj in cue_reconstructed:\n",
    "    labels = cue_labels_per_subj_per_ic.pop(0)\n",
    "    np.savez('/home/austin/PycharmProjects/BOWaves/data/cmmn_transformed_cue_to_emotion_ics/cue_reconstructed.npz', subj=subj, labels=labels)\n",
    "#np.savez('/home/austin/PycharmProjects/BOWaves/data/cue_reconstructed.npz', *cue_reconstructed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-07T20:53:20.342732220Z"
    }
   },
   "id": "c9c47e1eefdb4d73"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
